### [회고를 시작하며..]
 한 학기 동안 진행했던 캡스톤 프로젝트에서 운이 좋게도 금상을 수상하게 되었다. 우여곡절도 많았지만 각자의 위치에서 최선을 다하는 팀원들 덕분에 좋은 결과를 얻을 수 있었다고 생각한다. </br>
이번 프로젝트를 진행하면서 ‘소통’이란 것이 얼마나 중요한지, 그리고 그 내용을 명확히 정리하고 명세화하는 일이 얼마나 필요한지를 깊이 느낄 수 있었다. </br>
캡스톤 프로젝트를 통해 팀 구성원 모두가 하나의 목표를 향해 협업하는 과정을 직접 경험할 수 있어 매우 뜻깊었다. 이 소중한 경험을 글로 기록하여 나의 자산으로 남기는 것이 이번 회고의 개인적인 동기이다.</br>

### [우여곡절이 있던 초반 프로젝트]
 초기 프로젝트의 주제는 카메라 인식을 통한 정류장 혼잡도 측정으로, 대중교통을 이용하려는 사람들에게 버스 정류장의 혼잡도를 계산해 최적의 경로를 추천해주는 것이 목표였다. 그러나 여러 현실적인 문제에 부딪치게 되었다. </br></br>
 첫째, 비용 문제였다. 추천 시스템이 제대로 작동하려면 모든 정류장에 카메라가 설치되어 있어야 했다. </br></br>
 둘째, 대중교통을 이용해야만 하는 사람이라면 혼잡도와 상관없이 대중교통을 이용할 수 밖에 없다는 사실이다. </br></br>
그리고 근본적으로 정류장에서 기다리는 사람들이 어떤 버스를 탈것인지를 알 수 있는 방법이 없었다. 그래서 주제를 프로젝트 중간에 변경하게 되었다.</br>

 학기를 시작한지 3주차에 주제를 변경하기로 하게 되면서 절대적인 시간이 부족했다. 
 그래서 우리 팀만의 독창적인 아이디어를 구상하기보다는, 기존의 산업체 수요조사서에서 주제를 선정하기로 했다. 덕분에 관련 리소스를 제공받을 수 있었고, 빠르게 방향을 잡을 수 있었다.</br></br>
 새로운 주제는 아동이 동화 속 주인공이 되어, 자신의 얼굴과 목소리를 반영한 개인 맞춤형 컨텐츠를 경험할 수 있도록 하는 인터랙티브 동화 플랫폼을 만드는 것이었다.
 아이들의 목소리와 얼굴 이미지를 활용하여 동화가 생성되고, 이는 아이들의 능동적인 참여를 유도하는 것이 주된 목표였다.</br></br>
 AI 기술이 적용된 부분은 크게 두가지였다.</br></br>
첫째로, 사용자의 얼굴 이미지 정렬 기능이다. 사용자가 얼굴 이미지를 등록하면 크롭기능을 통해 얼굴을 정렬해서 이후 얼굴 이미지가 동화에 삽입될 때 보다 자연스럽게 표현될 수 있도록 했다.</br></br>
둘째로, 등록된 얼굴 이미지를 영상에 삽입하는 기술이었다. 사용자 얼굴이 들어가는 위치를 미리 마스킹 해두고, 영상을 생성할 때 AI를 통해 자동으로 해당 위치에 얼굴 이미지가 삽입되는 방식이었다. 그리고 정확도를 높이기 위해 추가적으로 프레임별 표정 정보를 담은 json파일을 활용했다.</br></br>

### [예상보다 느린 영상 생성속도]
 협력 기업체로부터 제공받은 영상은 금도끼 은도끼로 길이는 3분 30초정도였다. 
 그러나 영상 생성에는 7분이 넘는 시간이 소요되었다. 
 대안으로 스트리밍 방식도 고려를 해보았지만 이는 영상 생성시간이 영상 길이보다 적을 때만 의미 있다고 생각했다. 
 무엇보다 빠른 처리 속도 확보가 중요했다.
 
### [멀티 프로세싱을 통한 병렬처리가 항상 정답은 아니다]
<img width="732" alt="스크린샷 2025-06-14 오후 7 38 54" src="https://github.com/user-attachments/assets/4bb0456f-e487-4e3d-8cf6-2f8886b09925" />
</br>

 파이썬으로 작성된 코드를 확인해보니 단일 while루프로 프레임이 순차적으로 처리되고 있었다. 따라서 영상 생성 과정을 프레임 인식 / 처리 / 저장으로 나누고, 처리 단계에서 3개의 프로세서를 병렬로 할당하면 속도 향상이 있을 것이라 기대했다. 하지만 예상과 다른 결과가 나타났다.
 
 처음에는 프레임을 인식하면 큐에 보내고, 유휴 상태에 있는 프로세서가 이를 가져가는 구조로 설계했다. 해당 큐는 내부적으로 Lock이 작동해서 race condition이 발생하지 않고, 멀티 프로세싱에서 발생할 수 있는 문제에서 자유로웠다. 그러나 내부 큐의 lock때문에 처리 속도가 비슷하거나 오히려 느려졌다.</br></br>
 그래서 이번에는 프레임 인덱스를 기준으로 %3 분기문을 통해 각각의 worker queue에 명시적으로 작업을 할당했다. 대략 20-30%의 속도향상이 있었다. 
 프로세서의 수를 3배 늘렸으니 단순한 계산으로는 3배의 처리속도 향상을 기대할 수 있지만 context switching 오버헤드 때문인지 극적인 속도향상은 나타나지 않았고, 오히려 영상이 이상하게 생성되었다. 
 이는 영상 처리 로직이 이전 프레임 계산 결과를 활용하도록 구성되었는데 %3방식으로는 한 프로세서에 연속된 프레임이 할당되지 않기 때문이었다.</br></br>
 그래서 이번에는 영상을 3등분해서 각 프로세서가 독립적으로 처리를 한 후에 최종적으로 병합하는 방식을 시도해 보았다. 그러나 각 프로세서에 영상 메모리를 올려야 하기때문에 메모리 부족으로 중간에 중간에 터미널이 kill됐다.
 다양한 방법으로 시도해보았지만 마땅한 해결책이 존재하지 않는 것 같았다.

### [전처리를 통한 처리 속도 향상]
 나의 고민은 cpu bound 작업을 줄이는 것이 속도 향상의 유일한 해결책이라는 결론에 도달했다. 이에 따라 전체 영상의 각 프레임을 미리 계산한 뒤 파일에 저장하고, 영상 생성시에는 이 저장된 결과값을 활용하는 방식으로 전환했다. 
 결과는 극적이었다. </br></br>
 약 2배 이상의 속도향상 있었고, 영상도 잘 생성되었다. 이는 기존에는 “얼굴 프레임 계산 + 얼굴삽입” 이라는 두 작업이 cpu를 점유했지만, 전처리를 통해 “얼굴삽입”만 수행하게 되면서 CPU 계산량을 대폭 줄일 수 있었기 때문이다.

### [개선할 점 / 보완할 점 / 느낀점]
 이번 프로젝트에서는 백엔드 측면에서 복잡한 아키텍처를 설계 하거나 어려운 기능을 만들거나 하지는 않았고, 단순 CRUD수준에서 구현이 이루어졌다. 
 그럼에도 불구하고, 신뢰성 있는 소프트웨어를 목표로 삼아 예외처리에 중점을 두어 예외가 발생할 수 있는 다양한 케이스를 고민해보는 시간을 가졌었다. </br></br>
 그리고 나의 개인적인 욕심으로 ai 영상처리 속도 향상을 위해 노력했는데 이 과정에서 병렬처리 = 속도향상이 아니라는 지식을 경험적으로 깨달을 수 있어서 뜻깊은 경험이었다.</br></br>
 물론 아쉬운 점도 있었다. 시간부족으로 인해, 사용자의 음성 데이터기반으로 TTS를 동화에 적용하는 기능을 구현하지 못했다. 
 또한, 영상이 생성될 때마다 기존 영상이 삭제되지 않고 누적되는 방식인데, AOP를 통해 영상의 lifecycle을 로그에 기록하고, 스케줄러를 통해 영상을 주기적으로 삭제하는 방식을 도입하면 더 완성도 높은 소프트웨어가 되었을 거라고 생각한다.</br></br>
 이번 팀프로젝트를 하면서 많은 것을 배우고 값진 경험을 할 수 있어서 뜻 깊었고, 더불어 좋은 결과가 까지 얻을 수 있어 매우 만족한다.  각자의 위치에서 열심히 해준 팀원들에게도 고마운 마음이다. </br>
 아직 많이 부족하지만 성장 마인드셋을 잃지 않고 계속해서 발전하는 개발자가 되어 가치를 창출하고, 사회에 기여할 수 있는 사람이 되고 싶다.
